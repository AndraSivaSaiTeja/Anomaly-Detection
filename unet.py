# -*- coding: utf-8 -*-
"""unet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OmgRaE4e35EzY5fvkvDTII33FPVa3cjm
"""

import torch
import torch.nn as nn
import torchvision.models
from torchvision.models import  ResNet18_Weights

def convrelu(in_channels, out_channels, kernel, padding):
  return nn.Sequential(
    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),
    nn.ReLU(inplace=True),
  )


class ResNetUNet(nn.Module):
  def __init__(self, in_channels,out_channels):
    super().__init__()

    self.base_model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)
    #layer = self.base_model.conv1
    #new_layer = nn.Conv2d(in_channels=in_channels,out_channels=layer.out_channels,kernel=layer.kernel_stride,stride=layer.stride,padding=layer.padding,bias=layer.bias) 
    self.base_layers = list(self.base_model.children())
    self.in_channels=in_channels    

    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)
    self.layer0_1x1 = convrelu(64, 64, 1, 0)
    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)
    self.layer1_1x1 = convrelu(64, 64, 1, 0)
    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)
    self.layer2_1x1 = convrelu(128, 128, 1, 0)
    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)
    self.layer3_1x1 = convrelu(256, 256, 1, 0)
    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)
    self.layer4_1x1 = convrelu(512, 512, 1, 0)
    self.to3 = convrelu(in_channels,3,1,0)
    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)
    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)
    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)
    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)

    self.conv_original_size0 = convrelu(in_channels, 64, 3, 1)
    self.conv_original_size1 = convrelu(64, 64, 3, 1)
    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)

    self.conv_last = nn.Conv2d(64, out_channels, 1)

  def forward(self, input):
    x_original = self.conv_original_size0(input)
    x_original = self.conv_original_size1(x_original)

    layer0 = self.layer0(self.to3(input))
    layer1 = self.layer1(layer0)
    layer2 = self.layer2(layer1)
    layer3 = self.layer3(layer2)
    layer4 = self.layer4(layer3)

    layer4 = self.layer4_1x1(layer4)
    x = self.upsample(layer4)
    layer3 = self.layer3_1x1(layer3)
    if(self.in_channels==256):
        print(x.shape,layer3.shape)
        x = torch.cat([x, self.upsample(layer3)], dim=1)
    else:
        x = torch.cat([x,layer3],dim=1)
    x = self.conv_up3(x)

    x = self.upsample(x)
    layer2 = self.layer2_1x1(layer2)
    if(self.in_channels==256):
        print(x.shape,layer2.shape)
        x = torch.cat([x, self.upsample(layer2)], dim=1)
    else:
        x = torch.cat([x,layer2],dim=1) 
   # x = torch.cat([x, layer2], dim=1)
    x = self.conv_up2(x)

    x = self.upsample(x)
    layer1 = self.layer1_1x1(layer1)
    if(self.in_channels==256):
        print(x.shape,layer1.shape)
        x = torch.cat([x, self.upsample(layer1)], dim=1)
    else:
        x = torch.cat([x,layer1],dim=1)

    #x = torch.cat([x, layer1], dim=1)
    x = self.conv_up1(x)

    x = self.upsample(x)
    layer0 = self.layer0_1x1(layer0)
    if(self.in_channels==256):
        print(x.shape,layer0.shape)
        x = torch.cat([x, self.upsample(layer0)], dim=1)
    else:
        x = torch.cat([x,layer0],dim=1)
    
   # x = torch.cat([x, layer0], dim=1)
    x = self.conv_up0(x)

    x = self.upsample(x)
    if(self.in_channels==256):
        print(x.shape,x_original.shape)
        x = torch.cat([x, self.upsample(x_original)], dim=1)
    else:
        x = torch.cat([x,x_original],dim=1)

    #x = torch.cat([x, x_original], dim=1)
    x = self.conv_original_size2(x)

    out = self.conv_last(x)

    return out

#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#m0 = ResNetUNet(3,3)
#m0 = m0.to(device)
#m1 = ResNetUNet(64,64)
#m2 = ResNetUNet(128,128)
#m3 = ResNetUNet(256,256)

#input = torch.rand((1,3,256,256)).to(device)
#out = m0(input)
